# Assign the list from Python to R variables
input_names <- py$input_names
train_preds_list <- py$train_preds_list
test_preds_list <- py$test_preds_list
train_y <- py$train_y
test_y <- py$test_y
# Combine testing data into one DataFrame with 'Actual' and 'Predicted' columns
test_combined <- data.frame(
Predicted = test_preds_list[[1]][14, 'Predictions'][[1]],
Actual = test_y
)
# Calculate difference between actual and predicted
test_df <- test_combined %>%
mutate(Dif = Actual - Predicted)
# Calculate % error
test_df <- test_df %>%
mutate(perc_error = (Predicted - Actual)/ Predicted * 100)
# Extract the rownames and modify them to contain only the part before the first '_'
Group <- gsub("_.*", "", rownames(test_df))
# Add 'Group' and 'input_name' as new columns to the DataFrame
test_df$Group <- Group
View(test_df)
plz2 <- test_df %>% mutate(dataset = 'Chemical Data')
View(plz)
View(plz2)
View(plz)
plz2 <- plz2 %>% select(-rownames)
plz <- plz %>% select(-rownames)
plz3 <- rbind(plz, plz2)
plz2<-plz2 %>% select(-perc_error)
plz3 <- rbind(plz, plz2)
View(plz3)
p <- ggplot(plz3, aes(x = plz3$rownames, y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Measured Injury Protein (mg/mL)") +
geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 10, face = "bold"),
axis.title.y = element_text(size = 10, face = "bold"),
legend.title = element_blank(),
legend.text = element_text(size = 8),
legend.position = "bottom",
legend.spacing.y = unit(0.2, "cm"),
legend.justification = c(0, 0), # Moves the legend to the left
legend.box.just = "left"        # Aligns the legend within the box
) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_manual(values = custom_colors) +
facet_grid(~dataset, scales = "free", space = "free")  # Ensure each facet scales independently
p
View(plz3)
p <- ggplot(plz3, aes(x = rownames(plz3), y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Measured Injury Protein (mg/mL)") +
geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 10, face = "bold"),
axis.title.y = element_text(size = 10, face = "bold"),
legend.title = element_blank(),
legend.text = element_text(size = 8),
legend.position = "bottom",
legend.spacing.y = unit(0.2, "cm"),
legend.justification = c(0, 0), # Moves the legend to the left
legend.box.just = "left"        # Aligns the legend within the box
) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_manual(values = custom_colors) +
facet_grid(~dataset, scales = "free", space = "free")  # Ensure each facet scales independently
p
plz3$Group <- gsub("Smoldering", "Smold.", plz3$Group)
plz3$Group <- gsub("Flaming", "Flam.", plz3$Group)
plz3$Group <- gsub("([a-z])([A-Z])", "\\1 \\2", plz3$Group)
p <- ggplot(plz3, aes(x = rownames(plz3), y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Measured Injury Protein (mg/mL)") +
geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 10, face = "bold"),
axis.title.y = element_text(size = 10, face = "bold"),
legend.title = element_blank(),
legend.text = element_text(size = 8),
legend.position = "bottom",
legend.spacing.y = unit(0.2, "cm"),
legend.justification = c(0, 0), # Moves the legend to the left
legend.box.just = "left"        # Aligns the legend within the box
) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_manual(values = custom_colors) +
facet_grid(~dataset, scales = "free", space = "free")
p
# geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
# geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
p <- ggplot(plz3, aes(x = rownames(plz3), y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Measured Injury Protein (mg/mL)") +
# geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 10, face = "bold"),
axis.title.y = element_text(size = 10, face = "bold"),
legend.title = element_blank(),
legend.text = element_text(size = 8),
legend.position = "bottom",
legend.spacing.y = unit(0.2, "cm"),
legend.justification = c(0, 0), # Moves the legend to the left
legend.box.just = "left"        # Aligns the legend within the box
) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_manual(values = custom_colors) +
facet_grid(~dataset, scales = "free", space = "free")
p
p <- ggplot(plz3, aes(x = rownames(plz3), y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Measured Injury Protein (mg/mL)") +
geom_point(aes(y = Predicted), color = "red", size = 5, shape = 95) +  # Red dash for 'Predicted'
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 10, face = "bold"),
axis.title.y = element_text(size = 10, face = "bold"),
legend.title = element_blank(),
legend.text = element_text(size = 8),
legend.position = "bottom",
legend.spacing.y = unit(0.2, "cm"),
legend.justification = c(0, 0), # Moves the legend to the left
legend.box.just = "left"        # Aligns the legend within the box
) +
scale_y_continuous(expand = c(0, 0)) +
scale_fill_manual(values = custom_colors) +
facet_grid(~dataset, scales = "free", space = "free")
p
library(tidyverse)
library(reticulate)
repl_python()
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\jrchapp3\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
test_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
test_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
t
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
t
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
test_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_training_predictions_pysr_Full")
t
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
test_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
quit
train_y <- py$train_y
test_y <- py$test_y
train_y_pred <- py$train_y_pred
test_y_pred <- py$test_y_pred
test_preds_list <- py$test_preds_list
# Combine testing data into one DataFrame with 'Actual' and 'Predicted' columns
test_combined <- data.frame(
Predicted = test_preds_list[[3]][9, 'Predictions'][[1]],
Actual = test_y
)
# Combine training data into one DataFrame with 'Actual' and 'Predicted' columns
train_combined <- data.frame(
Actual = train_y,
Predicted = train_y_pred[,1]
)
View(test_combined)
# Combine training data into one DataFrame with 'Actual' and 'Predicted' columns
train_combined <- data.frame(
Actual = train_y,
Predicted = train_preds_list[[3]][9, 'Predictions'][[1]]
)
reticulate::repl_python()
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
t
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_train_y")
test_y = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Comb_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/Combined_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/4_ChemOmics_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
View(train_y_pred)
quit
df <- read.csv('..\\..\\3_Data_intermediates\\4_ChemOmics_measurements\\Comb_rmse_values_pysr_Elastic.csv')
# Load in summed importance values
dat_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_DEG.csv')
dat_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_PCA.csv')
dat_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_Elastic.csv')
# Put in list
dat_list <- list(dat_DEG, dat_pca, dat_elastic)
names(dat_list) <- c("DEG", "PCA", "Elastic")
# Load in full importance values
dat_all_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_DEG.csv')
dat_all_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_PCA.csv')
dat_all_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_Elastic.csv')
View(dat_all_elastic)
# Load in summed importance values
dat_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_DEG.csv')
dat_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_PCA.csv')
dat_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_Elastic.csv')
# Put in list
dat_list <- list(dat_DEG, dat_pca, dat_elastic)
names(dat_list) <- c("DEG", "PCA", "Elastic")
# Load in full importance values
dat_all_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_DEG.csv')
dat_all_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_PCA.csv')
dat_all_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_Elastic.csv')
# Put in list
dat_all_list <- list(dat_all_DEG, dat_all_pca, dat_all_elastic)
names(dat_all_list) <- c("DEG", "PCA", "Elastic")
# read in gene names
degs <- read.csv('..\\..\\1_Data_inputs\\3_Omic_measurements\\DEGs.csv') %>%
.[,4:5]
library(tidyverse)
library(reticulate)
library(tidytext)
library(gridExtra)
# Load in summed importance values
dat_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_DEG.csv')
dat_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_PCA.csv')
dat_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\variable_importance_Elastic.csv')
# Put in list
dat_list <- list(dat_DEG, dat_pca, dat_elastic)
names(dat_list) <- c("DEG", "PCA", "Elastic")
# Load in full importance values
dat_all_DEG <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_DEG.csv')
dat_all_pca <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_PCA.csv')
dat_all_elastic <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\pysr\\partial_deriv_Elastic.csv')
# Put in list
dat_all_list <- list(dat_all_DEG, dat_all_pca, dat_all_elastic)
names(dat_all_list) <- c("DEG", "PCA", "Elastic")
# read in gene names
degs <- read.csv('..\\..\\1_Data_inputs\\3_Omic_measurements\\DEGs.csv') %>%
.[,4:5]
genes <- read.csv('..\\..\\4_Model_results\\3_Omic_measurements\\all_genes_in_hof.csv')
# Rewrite cleaning function from python
clean_column_values <- function(df, column_name) {
df[[column_name]] <- sapply(df[[column_name]], function(name) {
if (name == "S") {
"Sulphur"
} else if (name == "Si") {
"Silicon"
} else {
cleaned_name <- gsub("\\W+", "", name) # Remove non-alphanumeric characters
cleaned_name <- gsub("([a-zA-Z])(\\d)", "\\1_\\2", cleaned_name) # Insert underscore between letters and digits
cleaned_name <- gsub("(\\d)([a-zA-Z])", "\\1_\\2", cleaned_name) # Insert underscore between digits and letters
if (grepl("^[0-9]", cleaned_name)) { # Check if the name starts with a digit
cleaned_name <- paste0("var", cleaned_name)
}
cleaned_name
}
})
return(df)
}
# Apply to biospyder IDs
degs_clean <- clean_column_values(degs, "BioSpyder_Identifier")
colnames(degs_clean)[1] <- 'gene'
# Clean names in dat_list
colnames(dat_list[[1]])[1] <- 'gene'
colnames(dat_list[[3]])[1] <- 'gene'
colnames(dat_list[[2]])[1] <- 'Gene_Symbol'
dat_list[[1]] <- left_join(dat_list[[1]], degs_clean, by = 'gene') %>%
select(-gene) %>%
unique()
dat_list[[3]] <- left_join(dat_list[[3]], degs_clean, by = 'gene') %>%
select(-gene) %>%
unique()
# Merge with gene names for IPA
genes_clean <- left_join(genes, degs_clean) %>%
select(Gene_Symbol) %>%
unique()
#write.csv(genes_clean, file = '..\\..\\4_Model_results\\3_Omic_measurements\\all_genes_in_hof_clean.csv' )
View(genes_clean)
# Names for the datasets
dataset_names <- c("DEG", "PCA", "Elastic")
# Combine all data into a single DataFrame with an identifier for each dataset
combined_dat <- do.call(rbind, lapply(1:length(dat_list), function(i) {
dat <- dat_list[[i]]
dat_top <- dat %>%
# mutate(var_importance = var_importance / uniq_instances) %>%
mutate(var_importance = var_importance / max(abs(var_importance))) %>%
arrange(desc(abs(var_importance))) %>%
mutate(Association = ifelse(var_importance > 0, "Positive", "Negative"))
# Subset only the top 15 for the first dataset
if (i == 1 | i == 3) {
dat_top <- dat_top[1:15, ]
}
# Add a column indicating the dataset name
dat_top$dataset <- dataset_names[i]
return(dat_top)
}))
# Set order
combined_dat$dataset <- factor(combined_dat$dataset, levels = c('DEG', 'PCA', 'Elastic'))
# Subset
combined_dat <- combined_dat %>%
filter(dataset == 'Elastic')
# Plot
p <- ggplot(combined_dat, aes(x = reorder_within(Gene_Symbol, -var_importance, dataset), y = var_importance, fill = Association)) +
geom_bar(stat = "identity") +
labs(x = "Gene Symbol", y = "Directional importance") +
scale_fill_manual(values = c("Positive" = "grey", "Negative" = "black")) +
scale_x_reordered() +  # Clean up x-axis labels
theme_classic() +
theme(
axis.text.x = element_text(size = 10, angle = 45, hjust = 1, face = "italic"), # Italicize x-axis labels
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold"),
legend.title = element_text(size = 12, face = "bold"),
legend.text = element_text(size = 8),
legend.position = "bottom"
)
# Print the combined plot
print(p)
# # Save
plot_filename <- paste0('..\\..\\5_Plots\\3_Omic_measurements/variable_importance_all.png')
# ggsave(plot_filename, p, width = 3.8, height = 4)
write.csv(genes_clean, file = '..\\..\\4_Model_results\\3_Omic_measurements\\all_genes_in_hof_clean.csv' )
top_diseases <- read.table('C://Users//jrchapp3//OneDrive - University of North Carolina at Chapel Hill//Symbolic_regression_github//NIH_Cloud_NOSI//4_Model_results//3_Omic_measurements//top_pathways.txt', header = TRUE, sep = "\t", stringsAsFactors = FALSE)
top_diseases <- read.table('C://Users//Jessie PC//OneDrive - University of North Carolina at Chapel Hill//Symbolic_regression_github//NIH_Cloud_NOSI//4_Model_results//3_Omic_measurements//top_pathways.txt', header = TRUE, sep = "\t", stringsAsFactors = FALSE)
top_diseases <- read.table('C://Users//Jessie PC//OneDrive - University of North Carolina at Chapel Hill//Symbolic_regression_github//NIH_Cloud_NOSI//4_Model_results//3_Omic_measurements//top_pathways.txt', header = TRUE, sep = "\t", stringsAsFactors = FALSE)
View(top_diseases)
# Function to extract the minimum p-value from the p.value string
extract_min_pval <- function(pvalue_str) {
# Split on hyphens not preceded by 'E'
pval_parts <- strsplit(pvalue_str, "(?<!E)-", perl = TRUE)[[1]]
# Remove any whitespace
pval_parts <- trimws(pval_parts)
# Convert to numeric
pvals <- as.numeric(pval_parts)
# Take the minimum value
min_pval <- min(pvals, na.rm = TRUE)
return(min_pval)
}
# Apply the function to the p.value column
top_diseases <- top_diseases %>%
mutate(
p_min = sapply(p.value, extract_min_pval),
p_transformed = -log10(p_min)  # Transform p-values to -log10 scale
)
# Apply the function to the p.value column
top_diseases <- top_diseases %>%
mutate(
p_min = sapply(X.log.p.value, extract_min_pval),
p_transformed = -log10(p_min)  # Transform p-values to -log10 scale
)
View(top_diseases)
# Apply the function to the p.value column
top_diseases <- top_diseases %>%
mutate(
p_min = sapply(X.log.p.value., extract_min_pval),
p_transformed = -log10(p_min)  # Transform p-values to -log10 scale
)
top_pathways <- read.table('C://Users//Jessie PC//OneDrive - University of North Carolina at Chapel Hill//Symbolic_regression_github//NIH_Cloud_NOSI//4_Model_results//3_Omic_measurements//top_pathways.txt', header = TRUE, sep = "\t", stringsAsFactors = FALSE)
# Remove null row
top_pathways <- top_pathways[-155,]
View(top_pathways)
top_pathways <- top_pathways %>%
mutate(
p_min = sapply(X.log.p.value., extract_min_pval),
p_transformed = -log10(p_min)  # Transform p-values to -log10 scale
)
# Clean up p-vals
colnames(top_pathways)[2] <- 'p_val'
colnames(top_pathways)[2] <- 'p.value'
# Subset the top 15 rows by p.value
top_15_diseases <- top_pathways %>%
arrange(p.value) %>%
slice(1:15)
View(top_15_diseases)
# Subset the top 15 rows by p.value
top_15_diseases <- top_pathways %>%
arrange(desc(p.value)) %>%
slice(1:15)
View(top_15_diseases)
# Read the data
top_pathways <- read.table('C://Users//Jessie PC//OneDrive - University of North Carolina at Chapel Hill//Symbolic_regression_github//NIH_Cloud_NOSI//4_Model_results//3_Omic_measurements//top_pathways.txt', header = TRUE, sep = "\t", stringsAsFactors = FALSE)
colnames(top_pathways)[2] <- 'p_transformed'
# Subset the top 15 pathways by the smallest p-value
top_15_pathways <- top_pathways %>%
arrange(-p_transformed) %>%
slice(1:15)
# Create the bar chart with adjustments
p <- ggplot(top_15_pathways, aes(x = reorder(Ingenuity.Canonical.Pathways, p_transformed), y = p_transformed)) +
geom_bar(stat = "identity") +
coord_flip() +  # Flip coordinates for better readability
labs(
x = NULL,  # Remove the 'Category' label
y = "-log10(p-value)",
title = "Top 15 Pathways by p-value"
) +
theme_classic() +
theme(
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 12),
axis.title.x = element_text(size = 16, face = "bold"),
axis.title.y = element_text(size = 16, face = "bold")
) +
scale_y_continuous(expand = c(0, 0))  # Remove padding to make bars touch x-axi
p
plot_filename <- paste0('C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/5_Plots/3_Omic_measurements/pathways.png')
ggsave(plot_filename, p, width = 7, height = 4)
p <- ggplot(top_15_pathways, aes(x = reorder(Ingenuity.Canonical.Pathways, p_transformed), y = p_transformed)) +
geom_bar(stat = "identity") +
coord_flip() +  # Flip coordinates for better readability
labs(
x = NULL,  # Remove the 'Category' label
y = "-log10(p-value)",
title = "Top 15 Pathways by p-value"
) +
theme_classic() +
theme(
axis.text.x = element_text(size = 8),
axis.text.y = element_text(size = 8),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
) +
scale_y_continuous(expand = c(0, 0))  # Remove padding to make bars touch x-axi
plot_filename <- paste0('C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/5_Plots/3_Omic_measurements/pathways.png')
ggsave(plot_filename, p, width = 7, height = 4)
-log10(0.05)

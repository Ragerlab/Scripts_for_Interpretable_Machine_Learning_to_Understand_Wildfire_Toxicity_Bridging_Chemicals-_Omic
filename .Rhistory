library(corrplot)
library(reticulate)
library(gridExtra)
reticulate::repl_python()
import pickle
import pandas as pd
injury_df = pd.read_pickle("C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/Data_inputs/2_Chemical_measurements/injury_df")
library(tidyverse)
library(reticulate)
library(Metrics)
library(tidytext)
library(pheatmap)
library(gridExtra)
library(ggpubr)
library(data.table)
# Datasets to process
datasets <- list(
list(
dataset = "2_Chemical_measurements",
dataset_name = "Chemical"
),
list(
dataset = "3_Omic_measurements",
dataset_name = "Omic"
)
)
for (d in datasets) {
dataset <- d$dataset
dataset_name <- d$dataset_name
print(paste("Processing dataset:", dataset_name))
# Initialize Python environment within R
use_python("path_to_your_python_executable", required = TRUE)  # Replace with your Python path
# Load Data in Python
py_run_string("
import pandas as pd
import os
# Set working directory
os.chdir(r'C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI')
for (d in datasets) {
dataset <- d$dataset
dataset_name <- d$dataset_name
print(paste("Processing dataset:", dataset_name))
# Initialize Python environment within R
use_python()  # Replace with your Python path
# Load Data in Python
py_run_string("
import pandas as pd
import os
# Set working directory
os.chdir(r'C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI')
2+2
library(tidyverse)
library(reticulate)
library(Metrics)
library(tidytext)
library(pheatmap)
library(gridExtra)
library(ggpubr)
library(data.table)
repl_python()
import pandas as pd
import os
# Datasets to process
datasets = [
{
"dataset": "2_Chemical_measurements",
"dataset_name": "Chemical"
},
{
"dataset": "3_Omic_measurements",
"dataset_name": "Omic"
}
]
# Set working directory
os.chdir(r'C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI')
# Load in data
train_y = pd.read_pickle(f'Data_inputs/{dataset}/train_y')
test_y = pd.read_pickle(f'Data_inputs/{dataset}/test_y')
train_y_pred = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Full')
test_y_pred = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Full')
train_y_pred_pca = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_PCA')
test_y_pred_pca = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_PCA')
train_y_pred_elastic = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Elastic')
test_y_pred_elastic = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Elastic')
train_y_pred_rf = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_rf_Full')
test_y_pred_rf = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_rf_Full')
# Store the inputs (Full, PCA, Elastic, RF) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
import pandas as pd
import os
# Set working directory
os.chdir(r'C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI')
# Datasets to process
datasets = [
{
"dataset": "2_Chemical_measurements",
"dataset_name": "Chemical"
},
{
"dataset": "3_Omic_measurements",
"dataset_name": "Omic"
}
]
# Initialize dictionaries to store data for each dataset
data_store = {}
for data_info in datasets:
dataset = data_info["dataset"]
dataset_name = data_info["dataset_name"]
# Load data
train_y = pd.read_pickle(f'Data_inputs/{dataset}/train_y')
test_y = pd.read_pickle(f'Data_inputs/{dataset}/test_y')
train_y_pred = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Full')
test_y_pred = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Full')
train_y_pred_pca = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_PCA')
test_y_pred_pca = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_PCA')
train_y_pred_elastic = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Elastic')
test_y_pred_elastic = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Elastic')
train_y_pred_rf = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_rf_Full')
test_y_pred_rf = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_rf_Full')
# Store inputs and predictions in lists
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
# Save all loaded data into a dictionary for this dataset
data_store[dataset_name] = {
"train_y": train_y,
"test_y": test_y,
"train_preds_list": train_preds_list,
"test_preds_list": test_preds_list,
"input_names": input_names
}
f'Data_inputs/{dataset}/train_y'
import pandas as pd
import os
# Set working directory
os.chdir(r'C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI')
# Datasets to process
datasets = [
{
"dataset": "2_Chemical_measurements",
"dataset_name": "Chem"
},
{
"dataset": "3_Omic_measurements",
"dataset_name": "Omic"
}
]
# Initialize dictionaries to store data for each dataset
data_store = {}
for data_info in datasets:
dataset = data_info["dataset"]
dataset_name = data_info["dataset_name"]
# Load data with prefixes
globals()[f'{dataset_name}_train_y'] = pd.read_pickle(f'Data_inputs/{dataset}/train_y')
globals()[f'{dataset_name}_test_y'] = pd.read_pickle(f'Data_inputs/{dataset}/test_y')
globals()[f'{dataset_name}_train_y_pred'] = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Full')
globals()[f'{dataset_name}_test_y_pred'] = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Full')
globals()[f'{dataset_name}_train_y_pred_pca'] = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_PCA')
globals()[f'{dataset_name}_test_y_pred_pca'] = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_PCA')
globals()[f'{dataset_name}_train_y_pred_elastic'] = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_Elastic')
globals()[f'{dataset_name}_test_y_pred_elastic'] = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_Elastic')
globals()[f'{dataset_name}_train_y_pred_rf'] = pd.read_pickle(f'Data_inputs/{dataset}/training_predictions_rf_Full')
globals()[f'{dataset_name}_test_y_pred_rf'] = pd.read_pickle(f'Data_inputs/{dataset}/test_predictions_rf_Full')
# Store inputs and predictions in lists
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [
globals()[f'{dataset_name}_train_y_pred'],
globals()[f'{dataset_name}_train_y_pred_pca'],
globals()[f'{dataset_name}_train_y_pred_elastic'],
globals()[f'{dataset_name}_train_y_pred_rf']
]
test_preds_list = [
globals()[f'{dataset_name}_test_y_pred'],
globals()[f'{dataset_name}_test_y_pred_pca'],
globals()[f'{dataset_name}_test_y_pred_elastic'],
globals()[f'{dataset_name}_test_y_pred_rf']
]
# Save all loaded data into a dictionary for this dataset
data_store[dataset_name] = {
f"{dataset_name}_train_y": globals()[f'{dataset_name}_train_y'],
f"{dataset_name}_test_y": globals()[f'{dataset_name}_test_y'],
"train_preds_list": train_preds_list,
"test_preds_list": test_preds_list,
"input_names": input_names
}
# Example: Access Chem dataset's test predictions
chem_test_preds = data_store["Chem"]["test_preds_list"]
quit
library(tidyverse)
library(reticulate)
library(Metrics)
repl_python()
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/train_y")
test_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y")
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y")
t
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y")
t
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y")
test_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
View(test_y)
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y.pkl")
import os
print(os.listdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI\3_Data_intermediates\2_Chemical_measurements"))
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_train_y")
test_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Chem_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
quit
# Assign the list from Python to R variables
input_names <- py$input_names
train_preds_list <- py$train_preds_list
test_preds_list <- py$test_preds_list
train_y <- py$train_y
test_y <- py$test_y
# Combine all testing data into a single DataFrame with identifiers for each dataset and input name
combined_test_dat <- do.call(rbind, lapply(seq_along(input_names), function(i) {
input_name <- input_names[[i]]
test_y_pred <- test_preds_list[[i]]
# Combine testing data into one DataFrame with 'Actual' and 'Predicted' columns
test_combined <- data.frame(
Actual = test_y,
Predicted = test_y_pred[,1]
)
# Calculate difference between actual and predicted
test_df <- test_combined %>%
mutate(Dif = Actual - Predicted)
# Calculate % error
test_df <- test_df %>%
mutate(perc_error = (Predicted - Actual)/ Predicted * 100)
# Extract the rownames and modify them to contain only the part before the first '_'
Group <- gsub("_.*", "", rownames(test_df))
# Add 'Group' and 'input_name' as new columns to the DataFrame
test_df$Group <- Group
test_df$input_name <- input_name
return(test_df)
}))
# Calculate normalized RMSE
nrmse <- rmse(combined_test_dat$Actual, combined_test_dat$Predicted) / (max(combined_test_dat$Actual)- min(combined_test_dat$Actual))
nrmse
# Define levels
combined_test_dat$input_name <- factor(combined_test_dat$input_name, levels = c('Full', 'PCA', 'Elastic', 'RF'))
# Clean up group labels
combined_test_dat$Group <- gsub("Smoldering", "Smold.", combined_test_dat$Group)
combined_test_dat$Group <- gsub("Flaming", "Flam.", combined_test_dat$Group)
combined_test_dat$Group <- gsub("([a-z])([A-Z])", "\\1 \\2", combined_test_dat$Group)
# Define the custom group order
custom_order <- c("Red Oak Flam.", "Pine Flam.", "Peat Flam.",
"Pine Needles Smold.", "Pine Needles Flam.",
"Eucalyptus Smold.", "Eucalyptus Flam.",
"Red Oak Smold.", "Pine Smold.", "Peat Smold.")
custom_order <- rev(custom_order)  # Reverse the order
# Update the Group variable with the custom order
combined_test_dat$Group <- factor(combined_test_dat$Group, levels = custom_order)
# Arrange the data by 'Group' and then by 'Actual' in descending order
combined_test_dat <- combined_test_dat %>%
arrange(desc(Group), desc(Actual))
# Update the x-axis with the reordered factor levels
combined_test_dat$rownames <- factor(rownames(combined_test_dat), levels = rownames(combined_test_dat))
# Subset
combined_test_dat <- combined_test_dat %>%
filter(input_name == 'Full')
# Define a custom color palette for the groups
custom_colors <- c(
"Pine Flam." = "#1b9e77",
"Peat Flam." = "#d95f02",
"Red Oak Smold." = "#7570b3",
"Eucalyptus Smold." = "#e7298a",
"Pine Needles Flam." = "#66a61e",
"Pine Needles Smold." = "#e6ab02",
"Red Oak Flam." = "#a6761d",
"Eucalyptus Flam." = "#666666",
"Pine Smold." = "#1f78b4",
"Peat Smold." = "#b2df8a"
)
# Set up the box plot using facet_wrap for each input_name
p <- ggplot(combined_test_dat, aes(x = Group, y = Dif, fill = Group)) +
geom_boxplot() +
geom_point(position = position_jitter(width = 0.2), alpha = 0.5) +
labs(x = "Group", y = "Actual - Predicted (mg/mL)") +
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold"),
legend.title=element_blank(),
legend.text = element_text(size = 10),
legend.position = "bottom"
) +
scale_fill_manual(values = custom_colors) +  # Apply the custom color palette
guides(fill = guide_legend(nrow = 3, byrow = TRUE)) +  # Adjust legend to have three rows
facet_wrap(~ input_name, scales = "free_x")
# Print the combined plot
print(p)
# Save
plot_filename <- paste0('C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/images/2_Chemical_measurements/pysr/Prediction_spread_all.png')
# ggsave(plot_filename, p, width = 7, height = 4)
# Set up the bar plot using facet_wrap for each input_name, using Individual_ID as the x-axis
p_bar <- ggplot(combined_test_dat, aes(x = combined_test_dat$rownames, y = Actual, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
geom_point(aes(y = Predicted), color = "red", size = 3, shape = 95) +  # Red dash for 'Predicted'
labs(x = "Individual", y = "Measured Injury Protein (ng/mL)") +
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 16, face = "bold"),
axis.title.y = element_text(size = 16, face = "bold"),
legend.title=element_blank(),
legend.text = element_text(size = 14),
legend.position = "bottom"
) +
scale_y_continuous(expand = c(0,0)) +
scale_fill_manual(values = custom_colors) +  # Apply the custom color palette
facet_wrap(~ input_name, scales = "free_x") +
guides(fill = guide_legend(nrow = 3, byrow = TRUE))  # Adjust legend to have three rows
plot_filename <- paste0('C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/images/2_Chemical_measurements/pysr/Prediction_vs_actual_all.png')
# ggsave(plot_filename, p_bar, width = 7, height = 4)
# Set up the bar plot using facet_wrap for each input_name, using Individual_ID as the x-axis
p_bar_two <- ggplot(combined_test_dat, aes(x = combined_test_dat$rownames, y = perc_error, fill = Group)) +
geom_bar(stat = "identity", alpha = 0.7) +  # Bars for 'Actual'
labs(x = "Individual", y = "Percent error") +
theme_classic() +
theme(
axis.text.x = element_blank(),  # Remove x-axis text labels
axis.title.x = element_text(size = 16, face = "bold"),
axis.title.y = element_text(size = 16, face = "bold"),
legend.title=element_blank(),
legend.text = element_text(size = 14),
legend.position = "bottom"
) +
scale_y_continuous(expand = c(0,0)) +
scale_fill_manual(values = custom_colors) +  # Apply the custom color palette
facet_wrap(~ input_name, scales = "free_x") +
guides(fill = guide_legend(nrow = 3, byrow = TRUE))  # Adjust legend to have three rows
# Save the plot
plot_filename_scatter <- paste0('C:/Users/Jessie PC/OneDrive - University of North Carolina at Chapel Hill/Symbolic_regression_github/NIH_Cloud_NOSI/images/2_Chemical_measurements/pysr/Actual_vs_Predicted_difference.png')
# ggsave(plot_filename_scatter, p_bar_two, width = 7, height = 4)
dat_full <- read.csv('..\\..\\NIH_Cloud_NOSI\\4_Model_results\\2_Chemical_measurements\\pysr\\variable_importance_Full.csv')
dat_full <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\variable_importance_Full.csv')
# Load in summed importance values
dat_full <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\variable_importance_Full.csv')
dat_pca <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\variable_importance_PCA.csv')
dat_elastic <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\variable_importance_Elastic.csv')
# Put in list
dat_list <- list(dat_full, dat_pca, dat_elastic)
# Load in full importance values
dat_all_full <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\partial_deriv_Full.csv')
dat_all_pca <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\partial_deriv_PCA.csv')
dat_all_elastic <- read.csv('..\\..\\4_Model_results\\2_Chemical_measurements\\pysr\\partial_deriv_Elastic.csv')
# Load in chemical categories
class <- read.csv('..\\..\\1_Data_inputs\\Chemical_categories.csv')
# Load in chemical categories
class <- read.csv('..\\..\\1_Data_inputs\\2_Chemical_measurements\\Chemical_categories.csv')
# Put in list
dat_all_list <- list(dat_all_full, dat_all_pca, dat_all_elastic)
names(dat_all_list) <- c("Full", "PCA", "Elastic")
clean_column_values <- function(column) {
# Apply cleaning logic to each element in the column
sapply(column, function(value) {
if (value == "S") {
return("Sulphur")
} else if (value == "Si") {
return("Silicon")
} else {
# Remove non-alphanumeric characters
cleaned_value <- gsub("\\W+", "", value)
# Add underscores between letters and numbers
cleaned_value <- gsub("([a-zA-Z])(\\d)", "\\1_\\2", cleaned_value)
cleaned_value <- gsub("(\\d)([a-zA-Z])", "\\1_\\2", cleaned_value)
# Add prefix if the value starts with a digit
if (grepl("^[0-9]", cleaned_value)) {
cleaned_value <- paste0("var", cleaned_value)
}
return(cleaned_value)
}
})
}
# Apply to the 'Chemical' column
class <- class %>%
mutate(chem = clean_column_values(Chemical))
# Count instances
class_count <- table(class$Chemical.Category) %>%
as.data.frame()
new_palette <- c(
"Inorganics" = "#f7a258",      # Soft orange
"Methoxyphenols" = "#8dd3c7",  # Light teal
"PAHs" = "#ff9dae",            # Soft pink
"Ions" = "#bebada",            # Pale purple
"n-Alkanes" = "#fb8072",
'Levoglucosan' = '#7F7F7F'
)
p <- ggplot(class_count, aes(x = reorder(Var1, -Freq), y = Freq, fill = Var1)) +
geom_bar(stat = "identity") +
labs(x = "Chemical class", y = "Chemicals targeted") +
theme_classic() +
theme(
axis.text.x = element_blank(),  # Removes the x-axis labels
axis.title.x = element_text(size = 16, face = "bold"),
axis.title.y = element_text(size = 16, face = "bold"),
legend.title = element_text(size = 16, face = "bold"),
legend.text = element_text(size = 14),
legend.position = "bottom"
) +
# facet_grid(. ~ Dataset, scales = "free_x", space = "free") +
scale_x_reordered() +  # Handles the reordered factors
scale_y_continuous(expand = c(0, 0)) +  # This removes the padding between bars and the x-axis
scale_fill_manual(values = new_palette) +
guides(fill = guide_legend(title = "Chemical Class", nrow = 2))
p
library(tidyverse)
library(reticulate)
repl_python()
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_train_y")
test_y = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/Omic_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/2_Chemical_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
import pandas as pd
import pickle
import os
# Set working directory
os.chdir(r"C:\Users\Jessie PC\OneDrive - University of North Carolina at Chapel Hill\Symbolic_regression_github\NIH_Cloud_NOSI")
# Load in data
train_y = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_train_y")
test_y = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_test_y")
train_y_pred = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_training_predictions_pysr_Full")
test_y_pred = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_test_predictions_pysr_Full")
train_y_pred_pca = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_training_predictions_pysr_PCA")
test_y_pred_pca = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_test_predictions_pysr_PCA")
train_y_pred_elastic = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_training_predictions_pysr_Elastic")
test_y_pred_elastic = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/Omic_test_predictions_pysr_Elastic")
train_y_pred_rf = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/training_predictions_rf_Full")
test_y_pred_rf = pd.read_pickle("3_Data_intermediates/3_Omic_measurements/test_predictions_rf_Full")
# Store the inputs (Full, PCA, Elastic) in a list
input_names = ['Full', 'PCA', 'Elastic', 'RF']
train_preds_list = [train_y_pred, train_y_pred_pca, train_y_pred_elastic, train_y_pred_rf]
test_preds_list = [test_y_pred, test_y_pred_pca, test_y_pred_elastic, test_y_pred_rf]
